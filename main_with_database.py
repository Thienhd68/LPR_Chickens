from PIL import Image
import cv2
import torch
import math 
import function.utils_rotate as utils_rotate
import function.helper as helper
import time
import os
import argparse
import json
from datetime import datetime
import sqlite3

# ===================== C·∫§U H√åNH DATABASE =====================
class LicensePlateDB:
    def __init__(self, db_path='license_plates.db'):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Kh·ªüi t·∫°o database v√† b·∫£ng"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS detected_plates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                plate_number TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                frame_number INTEGER,
                confidence REAL,
                image_path TEXT,
                source TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        print(f"‚úÖ Database ƒë√£ s·∫µn s√†ng: {self.db_path}")
    
    def save_plate(self, plate_number, frame_number, confidence=0.0, 
                   image_path=None, source='webcam'):
        """L∆∞u th√¥ng tin bi·ªÉn s·ªë v√†o database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            INSERT INTO detected_plates 
            (plate_number, timestamp, frame_number, confidence, image_path, source)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (plate_number, timestamp, frame_number, confidence, image_path, source))
        
        conn.commit()
        plate_id = cursor.lastrowid
        conn.close()
        
        return plate_id
    
    def get_recent_plates(self, limit=10):
        """L·∫•y danh s√°ch bi·ªÉn s·ªë g·∫ßn nh·∫•t"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM detected_plates 
            ORDER BY timestamp DESC 
            LIMIT ?
        ''', (limit,))
        
        plates = cursor.fetchall()
        conn.close()
        
        return plates
    
    def get_total_count(self):
        """ƒê·∫øm t·ªïng s·ªë bi·ªÉn s·ªë ƒë√£ ph√°t hi·ªán"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM detected_plates')
        count = cursor.fetchone()[0]
        
        conn.close()
        return count

# ===================== C·∫§U H√åNH =====================
parser = argparse.ArgumentParser(description='License Plate Detection')
parser.add_argument('--source', type=str, default='0', help='Ngu·ªìn video: 0 (webcam), 1, 2... ho·∫∑c ƒë∆∞·ªùng d·∫´n file video')
parser.add_argument('--save', action='store_true', help='L∆∞u video output')
parser.add_argument('--save-crops', action='store_true', help='L∆∞u ·∫£nh bi·ªÉn s·ªë ƒë√£ c·∫Øt')
args = parser.parse_args()

# Kh·ªüi t·∫°o database
db = LicensePlateDB()

# T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh bi·ªÉn s·ªë
if args.save_crops:
    os.makedirs('detected_plates', exist_ok=True)
    print("üìÅ Th∆∞ m·ª•c 'detected_plates' ƒë√£ s·∫µn s√†ng")

# T·∫£i model nh·∫≠n di·ªán bi·ªÉn v√† OCR bi·ªÉn s·ªë
print("‚è≥ ƒêang t·∫£i models...")
yolo_LP_detect = torch.hub.load('yolov5', 'custom', path='model/LP_detector.pt', force_reload=True, source='local')
yolo_license_plate = torch.hub.load('yolov5', 'custom', path='model/LP_ocr.pt', force_reload=True, source='local')
yolo_license_plate.conf = 0.60
print("‚úÖ Models ƒë√£ t·∫£i xong!")

# ===================== M·ªû NGU·ªíN VIDEO =====================
source = int(args.source) if args.source.isdigit() else args.source
cap = cv2.VideoCapture(source)

if not cap.isOpened():
    print(f"‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c ngu·ªìn: {source}")
    exit()

if isinstance(source, int):
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    print(f"üìπ ƒêang s·ª≠ d·ª•ng Camera {source}")
else:
    print(f"üé• ƒêang x·ª≠ l√Ω video: {source}")

# ===================== SETUP SAVE VIDEO =====================
out = None
if args.save:
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 20
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    output_path = f'output_{time.strftime("%Y%m%d_%H%M%S")}.mp4'
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))
    print(f"üíæ S·∫Ω l∆∞u video v√†o: {output_path}")

# ===================== BI·∫æN ƒê·∫æM FPS & TRACKING =====================
prev_frame_time = 0
new_frame_time = 0
frame_count = 0
detected_plates_history = {}  # L∆∞u l·ªãch s·ª≠ ƒë·ªÉ tr√°nh l∆∞u tr√πng
DETECTION_COOLDOWN = 30  # S·ªë frame ch·ªù tr∆∞·ªõc khi l∆∞u l·∫°i c√πng bi·ªÉn s·ªë

print("\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
print("‚å®Ô∏è  Nh·∫•n 'q' ƒë·ªÉ tho√°t")
print("‚å®Ô∏è  Nh·∫•n 'p' ƒë·ªÉ t·∫°m d·ª´ng/ti·∫øp t·ª•c")
print("‚å®Ô∏è  Nh·∫•n 's' ƒë·ªÉ ch·ª•p ·∫£nh m√†n h√¨nh")
print("‚å®Ô∏è  Nh·∫•n 'd' ƒë·ªÉ xem danh s√°ch bi·ªÉn s·ªë ƒë√£ l∆∞u\n")

paused = False

# ===================== V√íNG L·∫∂P CH√çNH =====================
while True:
    if not paused:
        ret, frame = cap.read()
        if not ret:
            print("‚úÖ Video ƒë√£ k·∫øt th√∫c ho·∫∑c l·ªói ƒë·ªçc frame.")
            break
        
        frame_count += 1
        
        # Ph√°t hi·ªán bi·ªÉn s·ªë
        plates = yolo_LP_detect(frame, size=640)
        list_plates = plates.pandas().xyxy[0].values.tolist()
        
        detected_plates = []
        
        for plate in list_plates:
            flag = 0
            x = int(plate[0])
            y = int(plate[1])
            w = int(plate[2] - plate[0])
            h = int(plate[3] - plate[1])
            confidence = plate[4]
            
            # V·∫Ω khung bi·ªÉn s·ªë
            crop_img = frame[y:y+h, x:x+w]
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
            
            # ƒê·ªçc bi·ªÉn s·ªë
            lp = ""
            for cc in range(0, 2):
                for ct in range(0, 2):
                    lp = helper.read_plate(yolo_license_plate, utils_rotate.deskew(crop_img, cc, ct))
                    if lp != "unknown":
                        detected_plates.append(lp)
                        
                        # Ki·ªÉm tra xem bi·ªÉn s·ªë n√†y ƒë√£ ƒë∆∞·ª£c l∆∞u g·∫ßn ƒë√¢y ch∆∞a
                        should_save = False
                        if lp not in detected_plates_history:
                            should_save = True
                        elif frame_count - detected_plates_history[lp] > DETECTION_COOLDOWN:
                            should_save = True
                        
                        # L∆∞u v√†o database n·∫øu c·∫ßn
                        if should_save:
                            image_path = None
                            if args.save_crops:
                                crop_filename = f'detected_plates/{lp}_{time.strftime("%Y%m%d_%H%M%S")}.jpg'
                                cv2.imwrite(crop_filename, crop_img)
                                image_path = crop_filename
                            
                            plate_id = db.save_plate(lp, frame_count, confidence, image_path, str(source))
                            detected_plates_history[lp] = frame_count
                            print(f"üíæ ƒê√£ l∆∞u bi·ªÉn s·ªë: {lp} (ID: {plate_id})")
                        
                        # V·∫Ω background cho text
                        text_size = cv2.getTextSize(lp, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0]
                        cv2.rectangle(frame, (x, y-35), (x + text_size[0], y), (0, 0, 255), -1)
                        cv2.putText(frame, lp, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)
                        flag = 1
                        break
                if flag == 1:
                    break
        
        # Hi·ªÉn th·ªã FPS
        new_frame_time = time.time()
        fps = int(1 / (new_frame_time - prev_frame_time + 1e-6))
        prev_frame_time = new_frame_time
        
        # V·∫Ω b·∫£ng th√¥ng tin
        info_bg = frame.copy()
        cv2.rectangle(info_bg, (5, 5), (300, 150), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.7, info_bg, 0.3, 0)
        
        cv2.putText(frame, f"FPS: {fps}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        cv2.putText(frame, f"Frame: {frame_count}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)
        cv2.putText(frame, f"Plates: {len(detected_plates)}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)
        cv2.putText(frame, f"Total DB: {db.get_total_count()}", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)
        
        # L∆∞u video n·∫øu ƒë∆∞·ª£c b·∫≠t
        if out is not None:
            out.write(frame)
    
    # Hi·ªÉn th·ªã video
    display_frame = frame.copy()
    if paused:
        cv2.putText(display_frame, "PAUSED - Press 'p' to continue", 
                    (frame.shape[1]//2 - 200, frame.shape[0]//2), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    
    cv2.imshow("License Plate Detection - Webcam", display_frame)
    
    # X·ª≠ l√Ω ph√≠m b·∫•m
    key = cv2.waitKey(1) & 0xFF
    
    if key == ord('q'):
        print("\nüõë D·ª´ng ch∆∞∆°ng tr√¨nh...")
        break
    elif key == ord('p'):
        paused = not paused
        if paused:
            print("‚è∏Ô∏è  T·∫°m d·ª´ng")
        else:
            print("‚ñ∂Ô∏è  Ti·∫øp t·ª•c")
    elif key == ord('s'):
        screenshot_path = f'screenshot_{time.strftime("%Y%m%d_%H%M%S")}.jpg'
        cv2.imwrite(screenshot_path, frame)
        print(f"üì∏ ƒê√£ l∆∞u ·∫£nh: {screenshot_path}")
    elif key == ord('d'):
        print("\n" + "="*50)
        print("üìã 10 BI·ªÇN S·ªê G·∫¶N NH·∫§T:")
        recent = db.get_recent_plates(10)
        for i, plate_data in enumerate(recent, 1):
            print(f"{i}. {plate_data[1]} - {plate_data[2]} (Frame: {plate_data[3]})")
        print("="*50 + "\n")

# ===================== GI·∫¢I PH√ìNG T√ÄI NGUY√äN =====================
cap.release()
if out is not None:
    out.release()
    print(f"‚úÖ ƒê√£ l∆∞u video output!")
cv2.destroyAllWindows()

print(f"\nüìä TH·ªêNG K√ä:")
print(f"   - T·ªïng s·ªë bi·ªÉn s·ªë ƒë√£ l∆∞u: {db.get_total_count()}")
print(f"   - T·ªïng s·ªë frame x·ª≠ l√Ω: {frame_count}")
print("üëã Ch∆∞∆°ng tr√¨nh k·∫øt th√∫c!")